# -*- coding: utf-8 -*-
"""Trial1(MFCC+Siamese CNN).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zatXdd_csW9XfYVygz-RdofKcnD7cYUh
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/STUDY/Project/ADD2023

import pandas as pd
label_path = "data/Track1.2/train/label.txt"

train_labels = {}
with open(label_path, "r") as f:
    for line in f:
        filename, label = line.strip().split()
        train_labels[filename] = label
print(f"총 {len(train_labels)}개의 라벨 로드 완료")
print(list(train_labels.items())[:5])  # 일부 확인

df_train_labels = pd.read_csv(label_path, sep=" ", header=None, names=["filename", "label"])
print(df_train_labels.head())
print(df_train_labels['label'].value_counts())  # fake / genuine 개수 확인

import os
import random
from tqdm import tqdm
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import datasets, transforms

from sklearn.metrics import roc_auc_score
from torch.utils.tensorboard import SummaryWriter

TRAIN_MFCC_DIR = "data/Track1.2/train/mfcc"
DEV_MFCC_DIR   = "data/Track1.2/dev/mfcc"
TRAIN_LABEL_PATH = "data/Track1.2/train/label.txt"
DEV_LABEL_PATH   = "data/Track1.2/dev/label.txt"

N_MFCC = 40
MAX_FRAMES = 400         # time-frames 길이 (파일에 따라 조정)
BATCH_SIZE = 64
EMBEDDING_DIM = 128
MARGIN = 0.3
LR = 1e-3
WEIGHT_DECAY = 1e-5
EPOCHS = 100
NUM_WORKERS = 2
DROPOUT = 0.3
ATTN_HEADS = 8
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
CHECKPOINT_DIR = "checkpoints"
LOG_DIR = "runs/siamese_triplet_stac"
SEED = 42

os.makedirs(CHECKPOINT_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)

def load_labels(path):
    df = pd.read_csv(path, sep=" ", header=None, names=["filename", "label"])
    df["label"] = df["label"].map({"fake": 0, "genuine": 1})
    return df

df_train_labels = load_labels(TRAIN_LABEL_PATH)
df_dev_labels = load_labels(DEV_LABEL_PATH)

print("Train:")
print(df_train_labels["label"].value_counts())
print("Dev:")
print(df_dev_labels["label"].value_counts())

class TripletMFCCDataset(Dataset):
    def __init__(self, df, mfcc_dir, n_mfcc, max_frames):
        self.df = df.copy()
        self.mfcc_dir = mfcc_dir
        self.n_mfcc = n_mfcc
        self.max_frames = max_frames

        self.filenames = self.df['filename'].tolist()
        self.labels = self.df['label'].tolist()
        self.genuine_idx = [i for i, l in enumerate(self.labels) if l == 1]
        self.fake_idx = [i for i, l in enumerate(self.labels) if l == 0]

        if len(self.genuine_idx) < 2:
            raise ValueError("Not enough genuine samples")
        if len(self.fake_idx) < 1:
            raise ValueError("Not enough fake samples")

    def __len__(self):
        return len(self.genuine_idx)

    def _load_and_pad(self, path):
        arr = np.load(path)  # expected shape: (n_mfcc, time_frames)
        if arr.ndim == 3:
            arr = arr.squeeze(0)

        # if input mfcc n_mfcc differs, try to adapt (trim or pad freq axis)
        if arr.shape[0] != self.n_mfcc:
            if arr.shape[0] > self.n_mfcc:
                arr = arr[:self.n_mfcc, :]
            else:
                pad_rows = self.n_mfcc - arr.shape[0]
                arr = np.concatenate([arr, np.zeros((pad_rows, arr.shape[1]), dtype=arr.dtype)], axis=0)

        t = arr.shape[1]
        if t >= self.max_frames:
            arr = arr[:, :self.max_frames]
        else:
            pad = self.max_frames - t
            arr = np.concatenate([arr, np.zeros((self.n_mfcc, pad), dtype=arr.dtype)], axis=1)

        arr = (arr - arr.mean()) / (arr.std() + 1e-8)
        return arr.astype(np.float32)

    def get_item_by_index(self, idx):
      fname = self.filenames[idx]
      path = os.path.join(self.mfcc_dir, fname.replace(".wav", ".npy"))
      if not os.path.exists(path):
        raise ValueError(f"File not found: {path}")
      mfcc = self._load_and_pad(path)
      mfcc = np.expand_dims(mfcc, axis=0)
      return torch.from_numpy(mfcc), self.labels[idx], fname

    def __getitem__(self, idx):
      # idx : index in genuine idx(anchor)
      anchor_idx = self.genuine_idx[idx]

      # choose positive (different genuine index)
      pos_idx = anchor_idx
      while pos_idx == anchor_idx:
        pos_idx = random.choice(self.genuine_idx)

      # choose negative (fake index)
      neg_idx = random.choice(self.fake_idx)

      anchor_mfcc, _, _ = self.get_item_by_index(anchor_idx)
      pos_mfcc, _, _ = self.get_item_by_index(pos_idx)
      neg_mfcc, _, _ = self.get_item_by_index(neg_idx)
      return anchor_mfcc, pos_mfcc, neg_mfcc

class SelfAttentionBlock(nn.Module):
  def __init__(self, embed_dim, n_heads):
    super().__init__()
    self.embed_dim = embed_dim
    self.n_heads = n_heads
    self.head_dim = embed_dim // n_heads

    self.attn = nn.MultiheadAttention(embed_dim, n_heads, batch_first=True)
    self.norm1 = nn.LayerNorm(embed_dim)
    self.ff = nn.Sequential( #Feed Forward
        nn.Linear(embed_dim, embed_dim),
        nn.ReLU(),
        nn.Linear(embed_dim, embed_dim)
    )
    self.norm2 = nn.LayerNorm(embed_dim)
    self.dropout = nn.Dropout(DROPOUT)

  def forward(self, x):
    attn_out, _ = self.attn(x, x, x) #query, key, value
    x = self.norm1(x + self.dropout(attn_out)) #residual connection + layer norm
    ff_out = self.ff(x)
    x = self.norm2(x + self.dropout(ff_out))
    return x

"""atten_output, _ = self.atten(x,x,x)

- 입력의 각 위치가 다른 모든 위치를 참조할 수 있게 함

- pytorch 문서 예시

  multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)

  attn_output, attn_output_weights = multihead_attn(query, key, value)

-----

*batch_first(default: False)

- If True, then the input and output tensors are provided as (batch, seq, feature). Default: False (seq, batch, feature).
"""

class SiameseBranch(nn.Module):
  def __init__(self, in_channels, n_mfcc, embedding_dim, attn_heads):
    super().__init__()

    self.conv1 = nn.Sequential(
        nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(32),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(2)
    )
    self.conv2 = nn.Sequential(
        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(64),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(2)
    )
    self.conv3 = nn.Sequential(
        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(128),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(2)
    )
    # after convs, we'll have shape (B, 128, H', W')
    # turn to sequence along time axis for attention: flatten freq x spatial -> seq_len
    self.proj = nn.Linear(128,128) # project channel dim if needed
    self.attn_block = SelfAttentionBlock(128, attn_heads)
    self.dropout = nn.Dropout(DROPOUT)

    self.fc = nn.Sequential(
        nn.AdaptiveAvgPool2d((1, 1)),
        nn.Flatten(),
        nn.Linear(128, 128),
        nn.ReLU(inplace=True),
        nn.Dropout(DROPOUT),
        nn.Linear(128, embedding_dim)
    )

  def forward(self, x):
    # x: (B, 1 ,n_mfcc, frames)
    x = self.conv1(x) # -> (B, 32, ~, ~)
    x2 = self.conv2(x) # -> (B, 64, ~, ~)
    x3 = self.conv3(x2) # -> (B, 128, ~, ~)

    #residual: add conv2 unsampled/proj to conv3 channels if sizes differ
    #ensure x2 -> same spatial dims as x3 by pooling/upsample if required
    if x2.shape[2:] != x3.shape[2:]:
      # up/downsample x2 spatial to x3 spatial
      x2_resized = F.interpolate(x2, size=x3.shape[2:], mode='bilinear', align_corners=False)
    else:
      x2_resized = x2
    # project channels 64->128
    if x2_resized.size(1) != x3.size(1):
      x2_projected = F.pad(x2_resized, (0,0,0,0,0, x3.size(1)-x2_resized.size(1)))
      # above is simple pad (works because x3 channels > x2 channels). Alternatively use conv.
    else:
      x2_projected = x2_resized
    x3 = x3 + x2_projected  # residual add

    # prepare for attention: (B, C, H, W) -> (B, seq_len, C) where seq_len = H*W
    B, C, H, W = x3.shape
    seq = x3.permute(0,2,3,1).reshape(B, H*W, C)  # (B, seq_len, C)
    seq = self.proj(seq)                          # (B, seq_len, 128)
    seq = self.attn_block(seq)                    # (B, seq_len, 128)

    # global pooling over seq dimension -> (B, 128)
    pooled = seq.mean(dim=1)
    out = pooled.unsqueeze(-1).unsqueeze(-1)  # (B,128,1,1) to feed fc
    emb = self.fc(out)  # (B, embedding_dim)
    emb = F.normalize(emb, p=2, dim=1)
    return emb

def compute_triplet_val_loss(model, df, mfcc_dir, criterion, n_mfcc, max_frames, max_samples=500):
    """
    Triplet Loss 기준으로 validation loss 계산
    """
    model.eval()
    total_loss = 0.0
    steps = 0

    df_eval = df.sample(min(len(df), max_samples), random_state=SEED)

    with torch.no_grad():
        for _, row in df_eval.iterrows():
            # anchor: genuine
            if row['label'] == 1:
                anchor_idx = row.name
            else:
                anchor_idx = random.choice(df_eval[df_eval['label']==1].index)

            # positive (다른 genuine)
            pos_idx = anchor_idx
            while pos_idx == anchor_idx:
                pos_idx = random.choice(df_eval[df_eval['label']==1].index)

            # negative (fake)
            neg_idx = random.choice(df_eval[df_eval['label']==0].index)

            # MFCC load & pad helper
            def load_mfcc(idx):
                fname = df_eval.loc[idx, 'filename']
                path = os.path.join(mfcc_dir, fname.replace(".wav", ".npy"))
                arr = np.load(path)
                if arr.ndim == 3: arr = arr.squeeze(0)
                if arr.shape[0] != n_mfcc:
                    if arr.shape[0] > n_mfcc:
                        arr = arr[:n_mfcc, :]
                    else:
                        pad_rows = n_mfcc - arr.shape[0]
                        arr = np.concatenate([arr, np.zeros((pad_rows, arr.shape[1]))], axis=0)
                t = arr.shape[1]
                if t >= max_frames:
                    arr = arr[:, :max_frames]
                else:
                    pad = max_frames - t
                    arr = np.concatenate([arr, np.zeros((n_mfcc, pad))], axis=1)
                arr = (arr - arr.mean()) / (arr.std() + 1e-8)
                return torch.from_numpy(arr).unsqueeze(0).unsqueeze(0).float().to(DEVICE)

            a = load_mfcc(anchor_idx)
            p = load_mfcc(pos_idx)
            n = load_mfcc(neg_idx)

            a_emb = model(a)
            p_emb = model(p)
            n_emb = model(n)

            loss = criterion(a_emb, p_emb, n_emb)
            total_loss += loss.item()
            steps += 1

    return total_loss / max(1, steps)

def train_loop(model, loader, optimizer, criterion, epoch, tb_writer):
    model.train()
    total_loss = 0.0
    steps = 0
    pbar = tqdm(loader, desc=f"Train Epoch {epoch}")
    for anchor, positive, negative in pbar:
        anchor = anchor.to(DEVICE)
        positive = positive.to(DEVICE)
        negative = negative.to(DEVICE)

        # forward
        a_emb = model(anchor)
        p_emb = model(positive)
        n_emb = model(negative)

        loss = criterion(a_emb, p_emb, n_emb)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        steps += 1
        if steps % 20 == 0:
            tb_writer.add_scalar("train/loss_step", loss.item(), epoch * 1000 + steps)

        pbar.set_postfix(loss=f"{total_loss/steps:.4f}")

    avg_loss = total_loss / max(1, steps)
    tb_writer.add_scalar("train/loss_epoch", avg_loss, epoch)
    return avg_loss

# ----------------------------
# Main training entry
# ----------------------------
def main():
    train_dataset = TripletMFCCDataset(df_train_labels, TRAIN_MFCC_DIR, N_MFCC, MAX_FRAMES)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=False)

    model = SiameseBranch(1, N_MFCC, EMBEDDING_DIM, ATTN_HEADS).to(DEVICE)
    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
    criterion = nn.TripletMarginLoss(margin=MARGIN, p=2)

    tb = SummaryWriter(LOG_DIR)
    best_loss = float('inf')

    for epoch in range(1, EPOCHS+1):
        avg_loss = train_loop(model, train_loader, optimizer, criterion, epoch, tb)
        print(f"[Epoch {epoch}] Loss={avg_loss:.4f}")

        # quick val AUC every 5 epochs
        if epoch % 5 == 0:
            val_loss = compute_triplet_val_loss(model, df_dev_labels, DEV_MFCC_DIR,
                                                criterion, N_MFCC, MAX_FRAMES, max_samples=500)

            tb.add_scalar("val/loss", val_loss, epoch)
            print(f"[Epoch {epoch}] Validation Loss={val_loss:.4f}")

            # best model 저장 (loss 기준)
            if val_loss < best_loss:
                best_loss = val_loss
                torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, "best_model.pt"))
                print("Saved new best model!")

        # save checkpoint
        ckpt = {
            'epoch': epoch,
            'model_state': model.state_dict(),
            'optimizer_state': optimizer.state_dict(),
            'loss': avg_loss
        }
        torch.save(ckpt, os.path.join(CHECKPOINT_DIR, f"siamese_epoch{epoch:03d}.pt"))

    tb.close()
    print("Training finished.")

if __name__ == "__main__":
    main()